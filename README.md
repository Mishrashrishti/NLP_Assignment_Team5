Dataset Curation, Cleaning, and Deduplication for Language Processing

This repository contains the code and resources for curating, cleaning, and deduplicating a language dataset. The project involves collecting data from publicly accessible sources, removing inappropriate content using custom-developed and existing bad-word dictionaries, and deduplicating the dataset using multiple robust techniques. The cleaned and deduplicated dataset is then used to train a tokenizer, with detailed statistics and analysis provided in the report.

Link for assignment 1 report - https://docs.google.com/document/d/19XPgk-LuuJt1TgOKGrEAA90_nVv8hYzCNIdbVmdoyg8/edit?usp=sharing





