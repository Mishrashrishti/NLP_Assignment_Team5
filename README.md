Dataset Curation, Cleaning, and Deduplication for Language Processing

This repository contains the code and resources for curating, cleaning, and deduplicating a language dataset. The project involves collecting data from publicly accessible sources, removing inappropriate content using custom-developed and existing bad-word dictionaries, and deduplicating the dataset using multiple robust techniques. The cleaned and deduplicated dataset is then used to train a tokenizer, with detailed statistics and analysis provided in the report.






